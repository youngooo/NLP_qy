{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging,jieba,os,re\n",
    "def get_stopwords():\n",
    "    logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',level=logging.INFO)\n",
    "    #加载停用词表\n",
    "    stopword_set = set()\n",
    "    with open(\"/root/wikiextractor-master/zhwiki/StopWords.txt\",'r',encoding=\"utf-8\") as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.add(stopword.strip(\"\\n\"))\n",
    "    return stopword_set\n",
    "\n",
    "'''\n",
    "使用正则表达式解析文本\n",
    "'''\n",
    "def parse_zhwiki(read_file_path,save_file_path):\n",
    "    #过滤掉<doc>\n",
    "    regex_str = \"[^<doc.*>$]|[^</doc>$]\"\n",
    "    file = open(read_file_path,\"r\",encoding=\"utf-8\")\n",
    "    #写文件\n",
    "    output = open(save_file_path,\"w+\",encoding=\"utf-8\")\n",
    "    content_line = file.readline()\n",
    "    #获取停用词表\n",
    "    stopwords = get_stopwords()\n",
    "     #定义一个字符串变量，表示一篇文章的分词结果\n",
    "    article_contents = \"\"\n",
    "    while content_line:\n",
    "        match_obj = re.match(regex_str,content_line)\n",
    "        content_line = content_line.strip(\"\\n\")\n",
    "        if len(content_line) > 0:\n",
    "            if match_obj:\n",
    "                #使用jieba进行分词\n",
    "                words = jieba.cut(content_line,cut_all=False)\n",
    "                for word in words:\n",
    "                    if word not in stopwords:\n",
    "                        article_contents += word+\" \"\n",
    "            else:\n",
    "                if len(article_contents) > 0:\n",
    "                    output.write(article_contents+\"\\n\")\n",
    "                    article_contents = \"\"\n",
    "        content_line = file.readline()\n",
    "    output.close()\n",
    "\n",
    "'''\n",
    "将维基百科语料库进行分类\n",
    "'''\n",
    "def generate_corpus():\n",
    "    zhwiki_path = \"/root/wikiextractor-master/zhwiki/AA\"\n",
    "    save_path = \"/root/wikiextractor-master/zhwiki/AA\"\n",
    "    for i in range(3):\n",
    "        file_path = os.path.join(zhwiki_path,str(\"wiki_1%s\"%str(i)))\n",
    "        parse_zhwiki(file_path,os.path.join(save_path,\"wiki_corpus0%s\"%str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2019-08-14 00:58:31,075:DEBUG:Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "2019-08-14 00:58:32,344:DEBUG:Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.496 seconds.\n",
      "2019-08-14 00:58:32,575:DEBUG:Loading model cost 1.496 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2019-08-14 00:58:32,578:DEBUG:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "generate_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
